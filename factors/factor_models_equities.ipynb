{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "intro",
   "metadata": {},
   "source": [
    "# Equity Factor Models\n",
    "\n",
    "This notebook constructs equity factor models similar to the crypto factor models:\n",
    "- **SMB (Size)**: Small minus Big based on market cap\n",
    "- **Value**: Based on earnings yield\n",
    "- **Momentum**: 12-1 month trailing returns\n",
    "- **Growth**: Based on revenue growth\n",
    "- **Quality**: ROE + Gross Margin - Debt/Equity\n",
    "- **Market**: Russell 1000 cap-weighted returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "imports",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "from typing import Optional\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import yfinance as yf\n",
    "\n",
    "# Local imports\n",
    "from utils import FactorModel, get_equity_data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "data-pull-header",
   "metadata": {},
   "source": [
    "## Data Pull\n",
    "Pull price data from yfinance. Fundamental data (earningsyield, pricetobook, etc.) deferred to future iteration \u2014 yfinance lacks historical structured fundamentals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pull-price-data",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pull equity price data via yfinance\n",
    "# Use a representative universe of large/mid cap tickers\n",
    "print('Pulling equity price data via yfinance...')\n",
    "\n",
    "# Russell 1000 representative tickers \u2014 expand as needed\n",
    "tickers = [\n",
    "    'AAPL', 'MSFT', 'AMZN', 'NVDA', 'GOOGL', 'META', 'TSLA', 'BRK-B', 'UNH', 'JNJ',\n",
    "    'V', 'XOM', 'JPM', 'PG', 'MA', 'HD', 'CVX', 'MRK', 'ABBV', 'LLY',\n",
    "    'PEP', 'KO', 'COST', 'AVGO', 'TMO', 'MCD', 'WMT', 'CSCO', 'ACN', 'ABT',\n",
    "    'DHR', 'NEE', 'LIN', 'ADBE', 'TXN', 'PM', 'RTX', 'HON', 'UNP', 'LOW',\n",
    "    'INTC', 'AMD', 'QCOM', 'COP', 'BMY', 'UPS', 'CAT', 'GE', 'BA', 'SPGI',\n",
    "    'DE', 'AMAT', 'GS', 'ELV', 'ADP', 'BLK', 'SYK', 'ISRG', 'MDLZ', 'GILD',\n",
    "    'LRCX', 'CB', 'REGN', 'VRTX', 'ADI', 'ZTS', 'SO', 'PGR', 'CI', 'CME',\n",
    "]\n",
    "\n",
    "# Download all at once for efficiency\n",
    "raw = yf.download(tickers, start='2020-01-01', progress=True, auto_adjust=True)\n",
    "\n",
    "# Build long-format price DataFrame\n",
    "records = []\n",
    "close_df = raw['Close'] if 'Close' in raw.columns.get_level_values(0) else raw\n",
    "volume_df = raw['Volume'] if 'Volume' in raw.columns.get_level_values(0) else None\n",
    "\n",
    "for ticker in tickers:\n",
    "    if ticker not in close_df.columns:\n",
    "        continue\n",
    "    prices = close_df[ticker].dropna()\n",
    "    for date, price in prices.items():\n",
    "        rec = {'ticker': ticker, 'date': date, 'price': price}\n",
    "        if volume_df is not None and ticker in volume_df.columns:\n",
    "            rec['volume'] = volume_df.loc[date, ticker]\n",
    "        records.append(rec)\n",
    "\n",
    "price_df = pd.DataFrame(records)\n",
    "price_df['date'] = pd.to_datetime(price_df['date'])\n",
    "price_df['ticker'] = price_df['ticker'].str.upper()\n",
    "print(f'Loaded {len(price_df):,} price records for {price_df[\"ticker\"].nunique():,} tickers')\n",
    "print(f'Date range: {price_df[\"date\"].min()} to {price_df[\"date\"].max()}')\n",
    "price_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pull-fundamental-data",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fundamental data (earningsyield, pricetobook, roe, etc.) NOT available from yfinance\n",
    "# in a reliable historical structured format. Deferring to future iteration.\n",
    "# For now, create empty fundamental_df placeholder so downstream cells can run with price-only factors.\n",
    "\n",
    "print('Fundamental data: DEFERRED \u2014 using price-only factors')\n",
    "fundamental_df = pd.DataFrame(columns=['ticker', 'date', 'metric', 'value'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pull-metadata",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Company metadata \u2014 derive from yfinance info or use static mapping\n",
    "# For now, use a simple sector mapping for the tickers we downloaded\n",
    "print('Building company metadata...')\n",
    "\n",
    "metadata_records = []\n",
    "for ticker in tickers:\n",
    "    try:\n",
    "        info = yf.Ticker(ticker).info\n",
    "        metadata_records.append({\n",
    "            'ticker': ticker,\n",
    "            'company_name': info.get('shortName', ''),\n",
    "            'sector': info.get('sector', ''),\n",
    "            'exchange': info.get('exchange', ''),\n",
    "        })\n",
    "    except Exception:\n",
    "        metadata_records.append({\n",
    "            'ticker': ticker,\n",
    "            'company_name': '',\n",
    "            'sector': '',\n",
    "            'exchange': '',\n",
    "        })\n",
    "\n",
    "metadata_df = pd.DataFrame(metadata_records)\n",
    "print(f'Loaded metadata for {len(metadata_df):,} companies')\n",
    "metadata_df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "data-prep-header",
   "metadata": {},
   "source": [
    "## Data Preparation\n",
    "Merge price and fundamental data, create Russell 1000 universe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "merge-data",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resample price data to monthly (end of month)\n",
    "print('Resampling price data to monthly...')\n",
    "\n",
    "price_df = price_df.set_index('date')\n",
    "price_monthly = price_df.groupby('ticker').resample('M').agg({\n",
    "    'price': 'last',\n",
    "    'volume': 'sum'\n",
    "}).reset_index()\n",
    "\n",
    "print(f'Monthly price data: {len(price_monthly):,} rows')\n",
    "\n",
    "# Calculate monthly returns\n",
    "price_monthly = price_monthly.sort_values(['ticker', 'date'])\n",
    "price_monthly['return_1m'] = price_monthly.groupby('ticker')['price'].pct_change(1)\n",
    "price_monthly['return_12m'] = price_monthly.groupby('ticker')['price'].pct_change(12)\n",
    "\n",
    "price_monthly.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "merge-fundamentals",
   "metadata": {},
   "outputs": [],
   "source": "# Expand annual fundamental data to monthly (forward fill until next annual report)\nprint('Processing fundamental data...')\n\nfundamental_df['date'] = pd.to_datetime(fundamental_df['date'])\n\n# Get the date range we need (from price data)\nmin_date = price_monthly['date'].min()\nmax_date = price_monthly['date'].max()\nall_months = pd.date_range(start=min_date, end=max_date, freq='M')\n\nprint(f'Expanding fundamentals to monthly from {min_date} to {max_date}')\n\n# For each ticker, create monthly rows and forward fill from annual data\ndef expand_to_monthly(group):\n    ticker = group['ticker'].iloc[0]\n    # Create a dataframe with all months\n    monthly_df = pd.DataFrame({'date': all_months})\n    monthly_df['ticker'] = ticker\n    # Merge with annual fundamental data\n    monthly_df = monthly_df.merge(group.drop(columns=['ticker']), on='date', how='left')\n    # Forward fill the fundamental values\n    monthly_df = monthly_df.ffill()\n    return monthly_df\n\nfundamental_monthly = fundamental_df.groupby('ticker').apply(expand_to_monthly).reset_index(drop=True)\nfundamental_monthly = fundamental_monthly.dropna(subset=['marketcap'])  # Drop rows before first fundamental data\n\nprint(f'Monthly fundamental data: {len(fundamental_monthly):,} rows, {fundamental_monthly[\"ticker\"].nunique()} tickers')\nprint(f'Date range: {fundamental_monthly[\"date\"].min()} to {fundamental_monthly[\"date\"].max()}')\nfundamental_monthly.head()"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "create-master-df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge price and fundamental data\n",
    "print('Merging price and fundamental data...')\n",
    "\n",
    "df = price_monthly.merge(\n",
    "    fundamental_monthly,\n",
    "    on=['ticker', 'date'],\n",
    "    how='inner'\n",
    ")\n",
    "\n",
    "# Add metadata\n",
    "df = df.merge(metadata_df, on='ticker', how='left')\n",
    "\n",
    "print(f'Master dataset: {len(df):,} rows, {df[\"ticker\"].nunique():,} tickers')\n",
    "print(f'Date range: {df[\"date\"].min()} to {df[\"date\"].max()}')\n",
    "print(f'Columns: {df.columns.tolist()}')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "create-russell1000",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Russell 1000 proxy - top 1000 stocks by market cap each month\n",
    "print('Creating Russell 1000 universe...')\n",
    "\n",
    "def get_russell1000_universe(group):\n",
    "    group = group.dropna(subset=['marketcap'])\n",
    "    if len(group) >= 1000:\n",
    "        group = group.nlargest(1000, 'marketcap')\n",
    "    group['in_russell1000'] = True\n",
    "    return group\n",
    "\n",
    "russell_universe = df.groupby('date').apply(get_russell1000_universe).reset_index(drop=True)\n",
    "print(f'Russell 1000 universe: {len(russell_universe):,} rows')\n",
    "\n",
    "# Filter to Russell 1000 only\n",
    "df_russell = russell_universe.copy()\n",
    "print(f'Filtered to Russell 1000: {len(df_russell):,} rows, {df_russell[\"ticker\"].nunique():,} unique tickers')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "utils-header",
   "metadata": {},
   "source": [
    "## Utility Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "utils",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cumulative_returns(factor_returns):\n",
    "    returns_df = pd.DataFrame(list(factor_returns.items()), columns=['date', 'value'])\n",
    "    returns_df['cumulative_returns'] = (1 + returns_df['value']).cumprod() - 1\n",
    "    return returns_df\n",
    "\n",
    "def calculate_factor_metrics(factor_returns_dict, factor_name):\n",
    "    returns_df = cumulative_returns(factor_returns_dict)\n",
    "    raw_returns = pd.Series(factor_returns_dict)\n",
    "    \n",
    "    sharpe = (raw_returns.mean() / raw_returns.std()) * np.sqrt(12)\n",
    "    downside = raw_returns[raw_returns < 0]\n",
    "    sortino = (raw_returns.mean() / downside.std()) * np.sqrt(12) if len(downside) > 0 else np.nan\n",
    "    \n",
    "    dates = list(factor_returns_dict.keys())\n",
    "    days = (dates[-1] - dates[0]).days\n",
    "    years = days / 365\n",
    "    cumulative = returns_df['cumulative_returns'].iloc[-1]\n",
    "    annualized = ((1 + cumulative) ** (1 / years)) - 1 if cumulative > -1 else np.nan\n",
    "    \n",
    "    return {\n",
    "        'factor': factor_name,\n",
    "        'annualized_return': annualized,\n",
    "        'cumulative_returns': cumulative,\n",
    "        'sharpe_ratio': sharpe,\n",
    "        'sortino_ratio': sortino,\n",
    "        'years': years,\n",
    "        'start_date': dates[0].strftime('%Y-%m-%d'),\n",
    "        'end_date': dates[-1].strftime('%Y-%m-%d'),\n",
    "    }, returns_df\n",
    "\n",
    "def plot_factor_performance(returns_df, factor_name, results_dict, long_only_df=None, short_only_df=None):\n",
    "    fig, ax1 = plt.subplots(figsize=(12, 6))\n",
    "    ax1.plot(returns_df['date'], returns_df['cumulative_returns'], linewidth=1.5, color='tab:blue', label='Factor (L-S)')\n",
    "    if long_only_df is not None:\n",
    "        ax1.plot(long_only_df['date'], long_only_df['cumulative_returns'], linewidth=1.5, color='tab:green', label='Long Only')\n",
    "    if short_only_df is not None:\n",
    "        ax1.plot(short_only_df['date'], short_only_df['cumulative_returns'], linewidth=1.5, color='tab:red', label='Short Only')\n",
    "    ax1.set_xlabel('Date')\n",
    "    ax1.set_ylabel('Cumulative Returns')\n",
    "    ax1.legend(loc='upper left')\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "    ax1.yaxis.set_major_formatter(plt.FuncFormatter(lambda x, _: '{:.0%}'.format(x)))\n",
    "    plt.title(f'{factor_name} Factor Performance')\n",
    "    metrics_text = f\"Ann. Return: {results_dict['annualized_return']:.1%}\\nSharpe: {results_dict['sharpe_ratio']:.2f}\\nPeriod: {results_dict['start_date']} to {results_dict['end_date']}\"\n",
    "    ax1.text(0.02, 0.98, metrics_text, transform=ax1.transAxes, fontsize=9, verticalalignment='top', bbox=dict(boxstyle='round', facecolor='white', alpha=0.8))\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "print('Utility functions loaded')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "smb-header",
   "metadata": {},
   "source": [
    "## SMB Factor (Size)\n",
    "Small minus Big - long small caps, short large caps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "smb-factor",
   "metadata": {},
   "outputs": [],
   "source": "print('Building SMB Factor...')\nBREAKPOINT = 0.3\nMIN_STOCKS = 10  # Reduced from 50 since we only have ~71 stocks with fundamental data\n\nsmb_factor_returns, smb_long_returns, smb_short_returns = {}, {}, {}\n\nfor date, group in df_russell.groupby('date'):\n    group = group.dropna(subset=['marketcap', 'return_1m'])\n    if len(group) < MIN_STOCKS:\n        continue\n    n_select = max(int(len(group) * BREAKPOINT), 5)\n    small_caps = group.nsmallest(n_select, 'marketcap')\n    big_caps = group.nlargest(n_select, 'marketcap')\n    small_return = small_caps['return_1m'].mean()\n    big_return = big_caps['return_1m'].mean()\n    smb_factor_returns[date] = small_return - big_return\n    smb_long_returns[date] = small_return\n    smb_short_returns[date] = big_return\n\nprint(f\"Generated {len(smb_factor_returns)} periods of SMB returns\")\nsmb_results, smb_returns_df = calculate_factor_metrics(smb_factor_returns, 'SMB')\nsmb_long_df, smb_short_df = cumulative_returns(smb_long_returns), cumulative_returns(smb_short_returns)\nprint(f\"SMB: Ann. Return: {smb_results['annualized_return']:.1%}, Sharpe: {smb_results['sharpe_ratio']:.2f}\")\nplot_factor_performance(smb_returns_df, 'SMB (Size)', smb_results, smb_long_df, smb_short_df)"
  },
  {
   "cell_type": "markdown",
   "id": "value-header",
   "metadata": {},
   "source": [
    "## Value Factor\n",
    "Long high earnings yield (cheap), short low earnings yield (expensive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "value-factor",
   "metadata": {},
   "outputs": [],
   "source": "print('Building Value Factor...')\nBREAKPOINT = 0.3\nMIN_STOCKS = 10\n\nvalue_factor_returns, value_long_returns, value_short_returns = {}, {}, {}\n\nfor date, group in df_russell.groupby('date'):\n    group = group.dropna(subset=['earningsyield', 'return_1m'])\n    group = group[(group['earningsyield'] > -1) & (group['earningsyield'] < 1)]\n    if len(group) < MIN_STOCKS:\n        continue\n    n_select = max(int(len(group) * BREAKPOINT), 5)\n    value_stocks = group.nlargest(n_select, 'earningsyield')\n    growth_stocks = group.nsmallest(n_select, 'earningsyield')\n    value_return = value_stocks['return_1m'].mean()\n    growth_return = growth_stocks['return_1m'].mean()\n    value_factor_returns[date] = value_return - growth_return\n    value_long_returns[date] = value_return\n    value_short_returns[date] = growth_return\n\nprint(f\"Generated {len(value_factor_returns)} periods of Value returns\")\nvalue_results, value_returns_df = calculate_factor_metrics(value_factor_returns, 'Value')\nvalue_long_df, value_short_df = cumulative_returns(value_long_returns), cumulative_returns(value_short_returns)\nprint(f\"Value: Ann. Return: {value_results['annualized_return']:.1%}, Sharpe: {value_results['sharpe_ratio']:.2f}\")\nplot_factor_performance(value_returns_df, 'Value (Earnings Yield)', value_results, value_long_df, value_short_df)"
  },
  {
   "cell_type": "markdown",
   "id": "momentum-header",
   "metadata": {},
   "source": [
    "## Momentum Factor\n",
    "12-1 month momentum - long winners, short losers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "momentum-factor",
   "metadata": {},
   "outputs": [],
   "source": "print('Building Momentum Factor...')\nMIN_STOCKS = 10\n\ndf_russell = df_russell.sort_values(['ticker', 'date'])\ndf_russell['price_lag1'] = df_russell.groupby('ticker')['price'].shift(1)\ndf_russell['price_lag12'] = df_russell.groupby('ticker')['price'].shift(12)\ndf_russell['momentum_12_1'] = (df_russell['price_lag1'] / df_russell['price_lag12']) - 1\n\nBREAKPOINT = 0.3\nmomentum_factor_returns, momentum_long_returns, momentum_short_returns = {}, {}, {}\n\nfor date, group in df_russell.groupby('date'):\n    group = group.dropna(subset=['momentum_12_1', 'return_1m'])\n    if len(group) < MIN_STOCKS:\n        continue\n    n_select = max(int(len(group) * BREAKPOINT), 5)\n    winners = group.nlargest(n_select, 'momentum_12_1')\n    losers = group.nsmallest(n_select, 'momentum_12_1')\n    winner_return = winners['return_1m'].mean()\n    loser_return = losers['return_1m'].mean()\n    momentum_factor_returns[date] = winner_return - loser_return\n    momentum_long_returns[date] = winner_return\n    momentum_short_returns[date] = loser_return\n\nprint(f\"Generated {len(momentum_factor_returns)} periods of Momentum returns\")\nmomentum_results, momentum_returns_df = calculate_factor_metrics(momentum_factor_returns, 'Momentum')\nmomentum_long_df, momentum_short_df = cumulative_returns(momentum_long_returns), cumulative_returns(momentum_short_returns)\nprint(f\"Momentum: Ann. Return: {momentum_results['annualized_return']:.1%}, Sharpe: {momentum_results['sharpe_ratio']:.2f}\")\nplot_factor_performance(momentum_returns_df, 'Momentum (12-1)', momentum_results, momentum_long_df, momentum_short_df)"
  },
  {
   "cell_type": "markdown",
   "id": "growth-header",
   "metadata": {},
   "source": [
    "## Growth Factor\n",
    "Long high revenue growth, short low revenue growth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "growth-factor",
   "metadata": {},
   "outputs": [],
   "source": "print('Building Growth Factor...')\nBREAKPOINT = 0.3\nMIN_STOCKS = 10\n\ngrowth_factor_returns, growth_long_returns, growth_short_returns = {}, {}, {}\n\nfor date, group in df_russell.groupby('date'):\n    group = group.dropna(subset=['revenuegrowth', 'return_1m'])\n    group = group[(group['revenuegrowth'] > -1) & (group['revenuegrowth'] < 5)]\n    if len(group) < MIN_STOCKS:\n        continue\n    n_select = max(int(len(group) * BREAKPOINT), 5)\n    high_growth = group.nlargest(n_select, 'revenuegrowth')\n    low_growth = group.nsmallest(n_select, 'revenuegrowth')\n    high_growth_return = high_growth['return_1m'].mean()\n    low_growth_return = low_growth['return_1m'].mean()\n    growth_factor_returns[date] = high_growth_return - low_growth_return\n    growth_long_returns[date] = high_growth_return\n    growth_short_returns[date] = low_growth_return\n\nprint(f\"Generated {len(growth_factor_returns)} periods of Growth returns\")\ngrowth_results, growth_returns_df = calculate_factor_metrics(growth_factor_returns, 'Growth')\ngrowth_long_df, growth_short_df = cumulative_returns(growth_long_returns), cumulative_returns(growth_short_returns)\nprint(f\"Growth: Ann. Return: {growth_results['annualized_return']:.1%}, Sharpe: {growth_results['sharpe_ratio']:.2f}\")\nplot_factor_performance(growth_returns_df, 'Growth (Revenue)', growth_results, growth_long_df, growth_short_df)"
  },
  {
   "cell_type": "markdown",
   "id": "quality-header",
   "metadata": {},
   "source": [
    "## Quality Factor\n",
    "Composite: z(ROE) + z(Gross Margin) - z(Debt/Equity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "quality-factor",
   "metadata": {},
   "outputs": [],
   "source": "print('Building Quality Factor...')\nMIN_STOCKS = 10\n\ndef calculate_quality_score(group):\n    group = group.copy()\n    for col in ['roe', 'grossmargin', 'debttoequity']:\n        if col in group.columns:\n            mean, std = group[col].mean(), group[col].std()\n            group[f'{col}_z'] = (group[col] - mean) / std if std > 0 else 0\n    group['quality_score'] = group.get('roe_z', 0) + group.get('grossmargin_z', 0) - group.get('debttoequity_z', 0)\n    return group\n\ndf_russell = df_russell.groupby('date').apply(calculate_quality_score).reset_index(drop=True)\n\nBREAKPOINT = 0.3\nquality_factor_returns, quality_long_returns, quality_short_returns = {}, {}, {}\n\nfor date, group in df_russell.groupby('date'):\n    group = group.dropna(subset=['quality_score', 'return_1m'])\n    if len(group) < MIN_STOCKS:\n        continue\n    n_select = max(int(len(group) * BREAKPOINT), 5)\n    high_quality = group.nlargest(n_select, 'quality_score')\n    low_quality = group.nsmallest(n_select, 'quality_score')\n    high_quality_return = high_quality['return_1m'].mean()\n    low_quality_return = low_quality['return_1m'].mean()\n    quality_factor_returns[date] = high_quality_return - low_quality_return\n    quality_long_returns[date] = high_quality_return\n    quality_short_returns[date] = low_quality_return\n\nprint(f\"Generated {len(quality_factor_returns)} periods of Quality returns\")\nquality_results, quality_returns_df = calculate_factor_metrics(quality_factor_returns, 'Quality')\nquality_long_df, quality_short_df = cumulative_returns(quality_long_returns), cumulative_returns(quality_short_returns)\nprint(f\"Quality: Ann. Return: {quality_results['annualized_return']:.1%}, Sharpe: {quality_results['sharpe_ratio']:.2f}\")\nplot_factor_performance(quality_returns_df, 'Quality (ROE+GM-D/E)', quality_results, quality_long_df, quality_short_df)"
  },
  {
   "cell_type": "markdown",
   "id": "market-header",
   "metadata": {},
   "source": [
    "## Market Factor\n",
    "Russell 1000 cap-weighted returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "market-factor",
   "metadata": {},
   "outputs": [],
   "source": "print('Building Market Factor...')\nMIN_STOCKS = 10\n\nmarket_factor_returns = {}\n\nfor date, group in df_russell.groupby('date'):\n    group = group.dropna(subset=['marketcap', 'return_1m'])\n    if len(group) < MIN_STOCKS:\n        continue\n    total_mcap = group['marketcap'].sum()\n    weighted_return = (group['marketcap'] * group['return_1m']).sum() / total_mcap\n    market_factor_returns[date] = weighted_return\n\nprint(f\"Generated {len(market_factor_returns)} periods of Market returns\")\nmarket_results, market_returns_df = calculate_factor_metrics(market_factor_returns, 'Market')\nprint(f\"Market: Ann. Return: {market_results['annualized_return']:.1%}, Sharpe: {market_results['sharpe_ratio']:.2f}\")\nplot_factor_performance(market_returns_df, 'Market (Cap-Weighted)', market_results)"
  },
  {
   "cell_type": "markdown",
   "id": "summary-header",
   "metadata": {},
   "source": [
    "## Factor Summary & Correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "factor-summary",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('=' * 60)\n",
    "print('EQUITY FACTOR SUMMARY')\n",
    "print('=' * 60)\n",
    "\n",
    "summary_df = pd.DataFrame({\n",
    "    'Factor': ['SMB', 'Value', 'Momentum', 'Growth', 'Quality', 'Market'],\n",
    "    'Ann. Return': [f\"{r['annualized_return']:.1%}\" for r in [smb_results, value_results, momentum_results, growth_results, quality_results, market_results]],\n",
    "    'Sharpe': [f\"{r['sharpe_ratio']:.2f}\" for r in [smb_results, value_results, momentum_results, growth_results, quality_results, market_results]],\n",
    "    'Cum. Return': [f\"{r['cumulative_returns']:.1%}\" for r in [smb_results, value_results, momentum_results, growth_results, quality_results, market_results]],\n",
    "})\n",
    "print(summary_df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "factor-correlation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Factor correlation matrix\n",
    "factor_returns_dict = {\n",
    "    'SMB': smb_factor_returns, 'Value': value_factor_returns, 'Momentum': momentum_factor_returns,\n",
    "    'Growth': growth_factor_returns, 'Quality': quality_factor_returns, 'Market': market_factor_returns,\n",
    "}\n",
    "\n",
    "factor_dfs = [pd.DataFrame(list(r.items()), columns=['date', n]).set_index('date') for n, r in factor_returns_dict.items()]\n",
    "all_factors_df = pd.concat(factor_dfs, axis=1).dropna()\n",
    "\n",
    "print('Factor Correlation Matrix:')\n",
    "print(all_factors_df.corr().round(2))\n",
    "\n",
    "# Plot comparison\n",
    "fig, ax = plt.subplots(figsize=(14, 8))\n",
    "colors = {'SMB': 'tab:blue', 'Value': 'tab:orange', 'Momentum': 'tab:green', 'Growth': 'tab:red', 'Quality': 'tab:purple', 'Market': 'tab:gray'}\n",
    "for col in all_factors_df.columns:\n",
    "    cum_ret = (1 + all_factors_df[col]).cumprod() - 1\n",
    "    ax.plot(cum_ret.index, cum_ret.values, linewidth=1.5, color=colors[col], label=col)\n",
    "ax.legend(loc='upper left')\n",
    "ax.grid(True, alpha=0.3)\n",
    "ax.yaxis.set_major_formatter(plt.FuncFormatter(lambda x, _: '{:.0%}'.format(x)))\n",
    "plt.title('Equity Factor Cumulative Returns')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "export-factors",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export\n",
    "all_factors_df.to_csv('equity_factor_returns.csv')\n",
    "print('Factor returns saved to equity_factor_returns.csv')\n",
    "\n",
    "equity_models = {\n",
    "    'smb': {'returns': smb_factor_returns, 'results': smb_results},\n",
    "    'value': {'returns': value_factor_returns, 'results': value_results},\n",
    "    'momentum': {'returns': momentum_factor_returns, 'results': momentum_results},\n",
    "    'growth': {'returns': growth_factor_returns, 'results': growth_results},\n",
    "    'quality': {'returns': quality_factor_returns, 'results': quality_results},\n",
    "    'market': {'returns': market_factor_returns, 'results': market_results},\n",
    "}\n",
    "print('Equity factor models ready!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9vwbghkoui",
   "source": "## Portfolio Factor Exposure Analysis\nMeasure how much exposure a portfolio has to each factor by regressing portfolio returns against factor returns.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "id": "07z3guhgimc9",
   "source": "import statsmodels.api as sm\n\ndef analyze_portfolio_factor_exposure(portfolio_returns, factor_returns_dict, portfolio_name=\"Portfolio\"):\n    \"\"\"\n    Regress portfolio returns against factor returns to measure factor exposures (betas).\n    \n    Args:\n        portfolio_returns: dict of {date: return} for the portfolio\n        factor_returns_dict: dict of {factor_name: {date: return}}\n        portfolio_name: name for display\n    \n    Returns:\n        DataFrame with factor betas and model object\n    \"\"\"\n    # Convert to DataFrames\n    portfolio_df = pd.DataFrame(list(portfolio_returns.items()), columns=['date', 'portfolio']).set_index('date')\n    \n    factor_dfs = []\n    for name, returns in factor_returns_dict.items():\n        df = pd.DataFrame(list(returns.items()), columns=['date', name]).set_index('date')\n        factor_dfs.append(df)\n    \n    factors_df = pd.concat(factor_dfs, axis=1)\n    \n    # Merge and align dates\n    merged = portfolio_df.merge(factors_df, left_index=True, right_index=True, how='inner')\n    \n    # Drop rows with NaN or inf values\n    merged = merged.replace([np.inf, -np.inf], np.nan).dropna()\n    \n    if len(merged) < 10:\n        print(f\"Warning: Only {len(merged)} overlapping periods after removing NaN/inf\")\n        return None, None\n    \n    # Run regression: portfolio = alpha + beta1*factor1 + beta2*factor2 + ...\n    y = merged['portfolio']\n    X = merged.drop(columns=['portfolio'])\n    X = sm.add_constant(X)\n    \n    model = sm.OLS(y, X).fit()\n    \n    # Build results table\n    results = []\n    for i, name in enumerate(['Alpha'] + list(factor_returns_dict.keys())):\n        results.append({\n            'Factor': name,\n            'Beta': model.params.iloc[i],\n            't-stat': model.tvalues.iloc[i],\n            'p-value': model.pvalues.iloc[i]\n        })\n    \n    results_df = pd.DataFrame(results)\n    \n    # Print results\n    print(f\"\\n{'='*60}\")\n    print(f\"FACTOR EXPOSURE ANALYSIS: {portfolio_name}\")\n    print(f\"{'='*60}\")\n    print(f\"Periods: {len(merged)} months\")\n    print(f\"R-squared: {model.rsquared:.3f}\")\n    print(f\"Adj R-squared: {model.rsquared_adj:.3f}\")\n    print(f\"\\nFactor Loadings (Betas):\")\n    print(\"-\" * 50)\n    for _, row in results_df.iterrows():\n        sig = \"***\" if row['p-value'] < 0.01 else \"**\" if row['p-value'] < 0.05 else \"*\" if row['p-value'] < 0.1 else \"\"\n        print(f\"  {row['Factor']:12s}: {row['Beta']:+.4f}  (t={row['t-stat']:+.2f}) {sig}\")\n    \n    print(\"-\" * 50)\n    print(\"Significance: *** p<0.01, ** p<0.05, * p<0.1\")\n    print(\"\\nInterpretation:\")\n    print(\"  Beta > 0: Portfolio has positive exposure to this factor\")\n    print(\"  Beta = 1: Portfolio moves 1:1 with the factor\")\n    print(\"  Beta < 0: Portfolio moves opposite to the factor\")\n    \n    return results_df, model\n\n# Create the factor returns dict for analysis\nequity_factor_returns = {\n    'SMB': smb_factor_returns,\n    'Value': value_factor_returns,\n    'Momentum': momentum_factor_returns,\n    'Growth': growth_factor_returns,\n    'Quality': quality_factor_returns,\n    'Market': market_factor_returns,\n}\n\nprint(\"Factor exposure analysis function ready!\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "ty0lawqjqdj",
   "source": "# Example: Analyze a sample portfolio's factor exposures\n# Replace 'my_portfolio_returns' with your portfolio's monthly returns as {date: return}\n\n# Example 1: Analyze the Quality long-only portfolio against all factors\nquality_long_exposure, quality_long_model = analyze_portfolio_factor_exposure(\n    portfolio_returns=quality_long_returns,\n    factor_returns_dict=equity_factor_returns,\n    portfolio_name=\"Quality Long-Only\"\n)",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "vw509lvckv",
   "source": "# Example 2: Analyze a custom portfolio\n# To use with your own portfolio, create a dict of {date: monthly_return}\n# \n# my_portfolio_returns = {\n#     pd.Timestamp('2023-01-31'): 0.05,   # 5% return in Jan 2023\n#     pd.Timestamp('2023-02-28'): -0.02,  # -2% return in Feb 2023\n#     # ... more months\n# }\n# \n# exposure_df, model = analyze_portfolio_factor_exposure(\n#     portfolio_returns=my_portfolio_returns,\n#     factor_returns_dict=equity_factor_returns,\n#     portfolio_name=\"My Portfolio\"\n# )\n\n# Example: Analyze the Value long-only portfolio\nvalue_long_exposure, value_long_model = analyze_portfolio_factor_exposure(\n    portfolio_returns=value_long_returns,\n    factor_returns_dict=equity_factor_returns,\n    portfolio_name=\"Value Long-Only\"\n)",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}